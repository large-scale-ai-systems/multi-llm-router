[AWS_BEDROCK]
# AWS Bedrock Configuration - REPLACE WITH YOUR ACTUAL CREDENTIALS
aws_access_key_id = AKIA_EXAMPLE_ACCESS_KEY_ID
aws_secret_access_key = example_secret_access_key_replace_with_actual
aws_region = us-west-2

[PROVIDER_CONFIGS]
# Claude Sonnet 4.0 Configuration
claude_model_id = us.anthropic.claude-sonnet-4-20250514-v1:0
claude_max_tokens = 4096
claude_temperature = 1.0
claude_timeout = 30

# GPT-4o Azure OpenAI Configuration
azure_openai_api_key = your_azure_openai_api_key_here
azure_openai_endpoint = https://your-resource.openai.azure.com/
azure_openai_api_version = 2024-12-01-preview

# Multiple OpenAI Model Deployments
openai_models = gpt4o,gpt4o-mini

# GPT-4o Configuration
gpt4o_deployment_name = your-gpt-4o-deployment
gpt4o_model_name = gpt-4o
gpt4o_max_tokens = 4096
gpt4o_temperature = 0.5
gpt4o_timeout = 30

# GPT-4o-mini Configuration
gpt4o-mini_deployment_name = your-gpt4o-mini-deployment
gpt4o-mini_model_name = o4-mini
gpt4o-mini_max_tokens = 4096
gpt4o-mini_temperature = 0.5
gpt4o-mini_timeout = 10

# Gemini Configuration
google_api_key = your_google_api_key_here
gemini_model = gemini-1.5-pro
gemini_max_tokens = 4096
gemini_temperature = 0.5
gemini_timeout = 30

[ROUTING_CONFIG]
# PID Controller Settings
kp = 1.0
ki = 0.1
kd = 0.05
setpoint = 0.5
min_response_time = 0.1
max_response_time = 30.0

# Vector Database Settings
vector_db_type = faiss
similarity_threshold = 0.15
max_results = 10

[SELECTION_WEIGHTS]
# LLM Selection Criteria Weights (must sum to 1.0)
# These weights determine how different factors influence LLM selection
golden_similarity = 0.4      # Accuracy against human evaluation data (primary factor) 40%%
relative_rank = 0.2          # How well LLM ranks compared to others 20%%
cost_efficiency = 0.15       # Cost-effectiveness of the response 15%%
time_efficiency = 0.15       # Response generation speed (set to 0.0 to ignore time) 15%%
uniqueness = 0.1             # Diversity and creativity factors 10%%

# Performance Tracking Configuration
ignore_performance_time = false     # Set to true to completely ignore timing in selection
focus_on_accuracy_only = false      # Set to true to prioritize only accuracy metrics
use_cost_optimization = true        # Set to false to ignore cost in selection

# Time-based Evaluation Settings
max_acceptable_response_time = 30.0  # Maximum acceptable response time (seconds)
time_penalty_threshold = 10.0        # Apply time penalty after this threshold (seconds)
time_penalty_factor = 0.1            # Penalty factor for slow responses

[MOCK_CONFIGS]
# Mock LLM Configuration for Testing
# gpt4_turbo settings
gpt4_turbo_base_response_time = 2.0
gpt4_turbo_quality_factor = 0.9
gpt4_turbo_error_rate = 0.02

# claude3_sonnet settings
claude3_sonnet_base_response_time = 1.5
claude3_sonnet_quality_factor = 0.85
claude3_sonnet_error_rate = 0.015

# gemini_pro settings
gemini_pro_base_response_time = 1.2
gemini_pro_quality_factor = 0.8
gemini_pro_error_rate = 0.025

[ALLOCATION_PERCENTAGES]
# Base allocation percentages for LLMs (must sum to 1.0)
# For real providers, use provider names from PROVIDER_CONFIGS
azure-openai-gpt4o = 0.33
azure-openai-gpt4o-mini = 0.34
bedrock-claude-sonnet-4 = 0.33
# google-gemini-pro = 0.20  # Commented out until valid API key is provided

# Mock LLM allocations (used for testing/demo mode)  
gpt4_turbo = 0.30
claude3_sonnet = 0.30
gemini_pro = 0.25
# Note: Remaining 0.15 will be distributed proportionally by the router